{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayes/chineseExample.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayes/chineseExample.txt\n",
    "D1\t1\tChinese Beijing\tChinese\n",
    "D2\t1\tChinese Chinese\tShanghai\n",
    "D3\t1\tChinese\tMacao\n",
    "D4\t0\tTokyo Japan\tChinese\n",
    "D5\t0\tChinese Chinese\tChinese Tokyo Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRNaiveBayesTrainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRNaiveBayesTrainer.py\n",
    "\n",
    "\"\"\"An implementation of wc as an MRJob.\n",
    "This is meant as an example of why mapper_final is useful.\"\"\"\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRNaiveBayesTrainer(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MRNaiveBayesTrainer, self).__init__(*args, **kwargs)\n",
    "        self.modelStats = {}\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        # Don't actually yield anything for each line. Instead, collect them\n",
    "        # and yield the sums when all lines have been processed. The results\n",
    "        # will be collected by the reducer.\n",
    "        docID, docClass,text = line.split(\"\\t\",2)   \n",
    "        words = text.split()\n",
    "        if docID != \"D5\":  #skip doc d5 in chinese dataset\n",
    "            if docClass == \"1\":\n",
    "                yield(\"TomsPriors\", \"0,1\")\n",
    "                for word in words:\n",
    "                    yield(word, \"0,1\")\n",
    "            else:\n",
    "                yield(\"TomsPriors\", \"1,0\")\n",
    "                for word in words:\n",
    "                    yield(word, \"1,0\")\n",
    "        \n",
    "\n",
    "    def reducer(self, word, values):\n",
    "        #aggregate counts for Pr(Word|Class)\n",
    "        #yield(\"number of values for \"+word, str(values))\n",
    "        w0Total=0\n",
    "        w1Total=0\n",
    "        for value in values:\n",
    "            w0, w1 =  value.split(\",\")\n",
    "            w0Total += float(w0)\n",
    "            w1Total += float(w1)  \n",
    "        self.modelStats[word] =  [w0Total, w1Total]\n",
    "\n",
    "        #yield(\"JIMI \"+word, [w0Total, w1Total])\n",
    "    def reducer_final(self):\n",
    "        \n",
    "        class0Total = 0\n",
    "        class1Total = 0\n",
    "        for k in self.modelStats.keys():\n",
    "            if k != \"TomsPriors\":\n",
    "                class0Total += self.modelStats[k][0]\n",
    "                class1Total += self.modelStats[k][1]\n",
    "        vocabularySize = len(self.modelStats.keys()) -1  #ignore TomsPriors\n",
    "        yield (\"defaultPrior 0 class\", class0Total+vocabularySize)\n",
    "        yield (\"defaultPrior 1 class\", class1Total+vocabularySize)\n",
    "        yield (\"count 0 class\", class0Total)\n",
    "        yield (\"count 1 class\", class1Total)\n",
    "        yield (\"vocabularySize\", vocabularySize)\n",
    "        #calculate priors \n",
    "        classCount0, classCount1 = self.modelStats.get(\"TomsPriors\")\n",
    "        del self.modelStats[\"TomsPriors\"]\n",
    "        total = classCount0 + classCount1\n",
    "        yield(\"TomsPriors\", ','.join(str(j) for j in [classCount0, classCount1, classCount0/total, classCount1/total])) \n",
    "        for k in self.modelStats.keys():\n",
    "            yield(k, ','.join(str(j) for j in [self.modelStats[k][0],\n",
    "                      self.modelStats[k][1],\n",
    "                      (self.modelStats[k][0] + 1) /(class0Total + vocabularySize), \n",
    "                      (self.modelStats[k][1] +1)/(class1Total+vocabularySize)]))        \n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRNaiveBayesTrainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "creating tmp directory /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473\n",
      "writing to /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/step-0-mapper-sorted\n",
      "> sort /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/step-0-mapper_part-00000\n",
      "writing to /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/step-0-reducer_part-00000 -> /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/output/part-00000\n",
      "Streaming final output from /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473/output\n",
      "\"defaultPrior 0 class\"\t9.0\n",
      "\"defaultPrior 1 class\"\t14.0\n",
      "\"count 0 class\"\t3.0\n",
      "\"count 1 class\"\t8.0\n",
      "\"vocabularySize\"\t6\n",
      "\"TomsPriors\"\t\"1.0,3.0,0.25,0.75\"\n",
      "\"Beijing\"\t\"0.0,1.0,0.111111111111,0.142857142857\"\n",
      "\"Chinese\"\t\"1.0,5.0,0.222222222222,0.428571428571\"\n",
      "\"Tokyo\"\t\"1.0,0.0,0.222222222222,0.0714285714286\"\n",
      "\"Shanghai\"\t\"0.0,1.0,0.111111111111,0.142857142857\"\n",
      "\"Japan\"\t\"1.0,0.0,0.222222222222,0.0714285714286\"\n",
      "\"Macao\"\t\"0.0,1.0,0.111111111111,0.142857142857\"\n",
      "removing tmp directory /var/folders/j4/95k348x940xcz40fkdmgy_n40000gn/T/MRNaiveBayesTrainer.jshanahan.20160616.135016.303473\n"
     ]
    }
   ],
   "source": [
    "!python MRNaiveBayesTrainer.py NaiveBayes/chineseExample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultPrior 0 class 9.0\n",
      "defaultPrior 1 class 14.0\n",
      "count 0 class 3.0\n",
      "count 1 class 8.0\n",
      "vocabularySize 6\n",
      "TomsPriors 1.0,3.0,0.25,0.75\n",
      "Beijing 0.0,1.0,0.111111111111,0.142857142857\n",
      "Chinese 1.0,5.0,0.222222222222,0.428571428571\n",
      "Tokyo 1.0,0.0,0.222222222222,0.0714285714286\n",
      "Shanghai 0.0,1.0,0.111111111111,0.142857142857\n",
      "Japan 1.0,0.0,0.222222222222,0.0714285714286\n",
      "Macao 0.0,1.0,0.111111111111,0.142857142857\n",
      "{'defaultPrior 0 class': 9.0, 'Shanghai': '0.0,1.0,0.111111111111,0.142857142857', 'Chinese': '1.0,5.0,0.222222222222,0.428571428571', 'count 1 class': 8.0, 'defaultPrior 1 class': 14.0, 'Tokyo': '1.0,0.0,0.222222222222,0.0714285714286', 'vocabularySize': 6, 'TomsPriors': '1.0,3.0,0.25,0.75', 'count 0 class': 3.0, 'Japan': '1.0,0.0,0.222222222222,0.0714285714286', 'Macao': '0.0,1.0,0.111111111111,0.142857142857', 'Beijing': '0.0,1.0,0.111111111111,0.142857142857'}\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy import random\n",
    "from MRNaiveBayesTrainer import MRNaiveBayesTrainer \n",
    "\n",
    "# STEP 1: Train a mulitnomial Naive Bayes      \n",
    "\n",
    "mr_job = MRNaiveBayesTrainer(args=['NaiveBayes/chineseExample.txt', '--file=NaiveBayes/model.txt'])\n",
    "modelStats={}\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "        # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print key, value\n",
    "        modelStats[key] = value\n",
    "            \n",
    "        # Update the centroids for the next iteration\n",
    "    with open('NaiveBayes/model1.txt', 'w') as f:\n",
    "        for k in modelStats.keys():\n",
    "            #f.writelines(k+\"\\t\"+modelStats[k])\n",
    "            f.writelines( k + \"\\t\"+ str(modelStats[k]) +\"\\n\")\n",
    "            #print k, modelStats[k][0]\n",
    "            #f.writelines(\"%s,%d,%d,%f,%f\" %(k, modelStats[k][0],modelStats[k][1],modelStats[k][2],modelStats[k][3]))\n",
    "\n",
    "            \n",
    "# STEP 2: Classify data with newly trained model      \n",
    "\n",
    "print modelStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultPrior 0 class\t9.0\r\n",
      "Shanghai\t0.0,1.0,0.111111111111,0.142857142857\r\n",
      "Chinese\t1.0,5.0,0.222222222222,0.428571428571\r\n",
      "count 1 class\t8.0\r\n",
      "defaultPrior 1 class\t14.0\r\n",
      "Tokyo\t1.0,0.0,0.222222222222,0.0714285714286\r\n",
      "vocabularySize\t6\r\n",
      "TomsPriors\t1.0,3.0,0.25,0.75\r\n",
      "count 0 class\t3.0\r\n",
      "Japan\t1.0,0.0,0.222222222222,0.0714285714286\r\n",
      "Macao\t0.0,1.0,0.111111111111,0.142857142857\r\n",
      "Beijing\t0.0,1.0,0.111111111111,0.142857142857\r\n"
     ]
    }
   ],
   "source": [
    "!cat NaiveBayes/model1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-784b5f1abaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaiveBayes/model.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: d"
     ]
    }
   ],
   "source": [
    "[map(float,s.split('\\n')[0].split(',')) for s in open(\"NaiveBayes/model.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRNaiveBayesTrainer.py  chineseExample.txt      model.txt.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls NaiveBayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
